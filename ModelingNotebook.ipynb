{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        ">[Modeling](#scrollTo=PMnoJMML6aiC)\n",
        "\n",
        ">>[Data Prep and Cleaning](#scrollTo=aoyYaNFL8Z53)\n",
        "\n",
        ">>[Train and Test Split](#scrollTo=pQYAAiTy8xAm)\n",
        "\n",
        ">>[Set Baseline](#scrollTo=CDoDEYVh9Dln)\n",
        "\n",
        ">>[Logisitic Regression](#scrollTo=O6vEyvtJ9SM9)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "x3FMNXxSINLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling\n",
        "**Amber Cash**\n",
        "\n",
        "The purpose of this notebook is to document the modeling process for my group's (STAR Analytics) submission for the Home Credit Kaggle competition. Below you will find my contribition, which was testing logistic regression models and assessing if they pass the performance benchmarks sets by themajority classifer model.\n",
        "\n"
      ],
      "metadata": {
        "id": "PMnoJMML6aiC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Prep and Cleaning\n",
        "\n",
        "To start, let's load in all packages and prepare the data for analysis. This includes aggregating data, joining our 3 data sets, and handling missing values by replacing them with the median value."
      ],
      "metadata": {
        "id": "aoyYaNFL8Z53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "# Load data\n",
        "train_data = pd.read_csv('application_train.csv')\n",
        "bureau_data = pd.read_csv('bureau.csv')\n",
        "previous_app_data = pd.read_csv('previous_application.csv')\n",
        "\n",
        "# Aggregate bureau data\n",
        "bureau_agg = bureau_data.groupby('SK_ID_CURR').agg({\n",
        "    'AMT_CREDIT_SUM': ['sum', 'mean'],\n",
        "    'AMT_CREDIT_SUM_DEBT': ['sum', 'mean'],\n",
        "    'AMT_CREDIT_SUM_OVERDUE': ['sum', 'mean'],\n",
        "    'CNT_CREDIT_PROLONG': ['sum']\n",
        "})\n",
        "bureau_agg.columns = ['_'.join(col).upper() for col in bureau_agg.columns]\n",
        "bureau_agg.reset_index(inplace=True)\n",
        "\n",
        "# Aggregate previous application data\n",
        "previous_app_agg = previous_app_data.groupby('SK_ID_CURR').agg({\n",
        "    'AMT_APPLICATION': ['mean', 'max'],\n",
        "    'AMT_CREDIT': ['mean', 'max'],\n",
        "    'DAYS_DECISION': ['mean'],\n",
        "    'NAME_CONTRACT_STATUS': ['count']\n",
        "})\n",
        "previous_app_agg.columns = ['_'.join(col).upper() for col in previous_app_agg.columns]\n",
        "previous_app_agg.reset_index(inplace=True)\n",
        "\n",
        "# Merge aggregated features with training data\n",
        "train_data = train_data.merge(bureau_agg, on='SK_ID_CURR', how='left')\n",
        "train_data = train_data.merge(previous_app_agg, on='SK_ID_CURR', how='left')\n",
        "\n",
        "# Select features and target\n",
        "features = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DAYS_BIRTH',\n",
        "            'AMT_CREDIT_SUM_SUM', 'AMT_CREDIT_SUM_MEAN', 'AMT_CREDIT_SUM_DEBT_SUM', 'AMT_CREDIT_SUM_DEBT_MEAN',\n",
        "            'AMT_APPLICATION_MEAN', 'AMT_APPLICATION_MAX', 'AMT_CREDIT_MEAN', 'AMT_CREDIT_MAX']\n",
        "target = 'TARGET'\n",
        "\n",
        "X = train_data[features]\n",
        "y = train_data[target]\n",
        "\n",
        "# Handle missing values (simple imputation)\n",
        "X.fillna(X.median(), inplace=True)"
      ],
      "metadata": {
        "id": "SOyR2raY8r99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Test Split\n",
        "\n",
        "Now, let's split our data into train and test split to use in our model training."
      ],
      "metadata": {
        "id": "pQYAAiTy8xAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)"
      ],
      "metadata": {
        "id": "7W_E6eiB84Ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Baseline\n",
        "\n",
        "Now, let's train our baseline - a majority classifier. We will use the performance metrics from this model as a benchmark while testing other models."
      ],
      "metadata": {
        "id": "CDoDEYVh9Dln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline model: Majority class classifier (predicts the most frequent class)\n",
        "majority_class = y_train.mode()[0]\n",
        "y_majority_pred = np.full_like(y_val, majority_class)\n",
        "majority_accuracy = accuracy_score(y_val, y_majority_pred)\n",
        "print(f'Majority Class Accuracy: {majority_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qasOg0H87d5",
        "outputId": "93feec8b-323d-4c83-9190-fb530a50f578"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Majority Class Accuracy: 0.9193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logisitic Regression\n",
        "\n",
        "Finally, let's train two logistic regression models (one default and one interaction term) to see if we can beat the beanchmark performance metrics."
      ],
      "metadata": {
        "id": "O6vEyvtJ9SM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform k-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Fit logistic regression model with cross-validation\n",
        "model = LogisticRegression()\n",
        "cross_val_auc = cross_val_score(model, X_train_scaled, y_train, cv=kf, scoring='roc_auc')\n",
        "print(f'Cross-Validation AUC: {cross_val_auc.mean():.4f}')\n",
        "\n",
        "# Train logistic regression model on full training set\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_val_scaled)\n",
        "y_prob = model.predict_proba(X_val_scaled)[:, 1]\n",
        "\n",
        "# Evaluate model\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "roc_auc = roc_auc_score(y_val, y_prob)\n",
        "\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')\n",
        "print(f'Validation ROC AUC Score: {roc_auc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhPRusf29hW4",
        "outputId": "18247fa2-8fb4-47f3-8fa9-38596d88995a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation AUC: 0.6288\n",
            "Validation Accuracy: 0.9192\n",
            "Validation ROC AUC Score: 0.6243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that a basic logistic regression model did not outperform our benchmark. Let's try introducing an interaction term to improve accuracy."
      ],
      "metadata": {
        "id": "GHH2yymg9q3n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WXgz3x58zHk5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7deca19-c38f-4053-a653-b593adf2d495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy with Interaction: 0.9192\n",
            "Validation ROC AUC Score with Interaction: 0.6243\n"
          ]
        }
      ],
      "source": [
        "# Fit logistic regression models with interaction terms\n",
        "X_train['INCOME_CREDIT_RATIO'] = X_train['AMT_INCOME_TOTAL'] / X_train['AMT_CREDIT']\n",
        "X_val['INCOME_CREDIT_RATIO'] = X_val['AMT_INCOME_TOTAL'] / X_val['AMT_CREDIT']\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "model_interaction = LogisticRegression()\n",
        "model_interaction.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_interaction = model_interaction.predict(X_val_scaled)\n",
        "y_prob_interaction = model_interaction.predict_proba(X_val_scaled)[:, 1]\n",
        "\n",
        "# Evaluate interaction model\n",
        "accuracy_interaction = accuracy_score(y_val, y_pred_interaction)\n",
        "roc_auc_interaction = roc_auc_score(y_val, y_prob_interaction)\n",
        "\n",
        "print(f'Validation Accuracy with Interaction: {accuracy_interaction:.4f}')\n",
        "print(f'Validation ROC AUC Score with Interaction: {roc_auc_interaction:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, we see this logistic regression fail to outperform the benchmark.\n",
        "\n",
        "Based on these results, we can assume that logistic regression is not the best fit for this data. It is likely that this model cannot handle the complexities of the Home Credit data. For that reason, STAR Analytics ultimately used an XG Boost model instead. That model was able to outperform the benchmark, providing promising predictive power."
      ],
      "metadata": {
        "id": "-GjKlXlJ9e4-"
      }
    }
  ]
}
